[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Luka Nguyen’s Blog",
    "section": "",
    "text": "Simple MLP model for Guitar Steel vs Nylon strings classification\n\n\n\n\n\n\n\ncode\n\n\nClassification\n\n\nmlp\n\n\ncnn\n\n\naudio\n\n\nprocessing\n\n\nsignal\n\n\nfft\n\n\n\n\n\n\n\n\n\n\n\nNov 26, 2022\n\n\nLuka Nguyen\n\n\n\n\n\n\n  \n\n\n\n\nVietnamese Lyrics Classification\n\n\n\n\n\n\n\ncode\n\n\nClassification\n\n\ndecision tree\n\n\n\n\n\n\n\n\n\n\n\nOct 21, 2022\n\n\nLuka Nguyen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Hello!"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Simple MLP model for Guitar Steel vs Nylon strings classification\n\n\n\n\n\n\n\ncode\n\n\nClassification\n\n\nmlp\n\n\ncnn\n\n\naudio\n\n\nprocessing\n\n\nsignal\n\n\nfft\n\n\n\n\n\n\n\n\n\n\n\nNov 26, 2022\n\n\nLuka Nguyen\n\n\n\n\n\n\n  \n\n\n\n\nVietnamese Lyrics Classification\n\n\n\n\n\n\n\ncode\n\n\nClassification\n\n\ndecision tree\n\n\n\n\n\n\n\n\n\n\n\nOct 21, 2022\n\n\nLuka Nguyen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/steel-nylon-classifier.html",
    "href": "posts/steel-nylon-classifier.html",
    "title": "Simple MLP model for Guitar Steel vs Nylon strings classification",
    "section": "",
    "text": "Can a 2-hidden-layer MLP do a good job classifying musical instrument sounds? Let’s find out!"
  },
  {
    "objectID": "posts/steel-nylon-classifier.html#download-audio-from-youtube",
    "href": "posts/steel-nylon-classifier.html#download-audio-from-youtube",
    "title": "Simple MLP model for Guitar Steel vs Nylon strings classification",
    "section": "4.1 Download audio from YouTube",
    "text": "4.1 Download audio from YouTube\nThese are the clips that I handpicked from YouTube. They are solo guitar recordings and were recorded in a professional studio. To watch any of them, just add the youtube url prefix. For example: “foIPN-T7RGo” ➡️ “youtube.com/watch?v=foIPN-T7RGo”\n\nsteel_clips = [\"foIPN-T7RGo\",\"10ATKnZLg9c\",\"IP8vBL5Q8Ac\"]\nnylon_clips = [\"qgb-bdEEI-M\",\"qXwvz-nTiog\",\"6jQ34uTmA9s\"]\n\nNext, we define our function to download and extract audio from a YouTube url:\n\nfrom pytube import YouTube\n\ndef download_youtube_mp3(link, output_dir):\n    \"\"\"\n    Download and extract audio from a clip from youtube \n    \"\"\"\n    yt=YouTube(f\"youtube.com/watch?v={link}\")\n    t=yt.streams.filter(only_audio=True).first().download(output_dir, link + \".mp3\")\n    print(f\"Downloaded YouTube Audio from: {link}\")\n\nEach clip is over 60 minutes long, which could take a long time to download. To accelerate, we will create a downloading thread for each clip and download all clips simultaneously.\n\ndownload_thread_list = []\n\nfor link in steel_clips:\n  new_thread = threading.Thread(target=download_youtube_mp3, args=(link, RAW_CLIP_PATH + \"steel\"))\n  download_thread_list.append(new_thread)\n\nfor link in nylon_clips:\n  new_thread = threading.Thread(target=download_youtube_mp3, args=(link, RAW_CLIP_PATH + \"nylon\"))\n  download_thread_list.append(new_thread)\n\n\nprint(\"Download Raw Clips starting...\")\n# start each thread\nfor thread in download_thread_list:\n  thread.start()\n\n# wait for all to finish\nfor thread in download_thread_list:\n  thread.join()\n\n# successfully excecuted\nprint(\"Download Raw Clips finished!\")\n\nDownload Raw Clips starting...\nDownloaded YouTube Audio from: foIPN-T7RGo\nDownloaded YouTube Audio from: 6jQ34uTmA9s\nDownloaded YouTube Audio from: qgb-bdEEI-M\nDownloaded YouTube Audio from: qXwvz-nTiog\nDownloaded YouTube Audio from: 10ATKnZLg9c\nDownloaded YouTube Audio from: IP8vBL5Q8Ac\nDownload Raw Clips finished!"
  },
  {
    "objectID": "posts/steel-nylon-classifier.html#segmentize-into-5-second-clips",
    "href": "posts/steel-nylon-classifier.html#segmentize-into-5-second-clips",
    "title": "Simple MLP model for Guitar Steel vs Nylon strings classification",
    "section": "4.2 Segmentize into 5-second clips",
    "text": "4.2 Segmentize into 5-second clips\nNow, let’s create some function to segment each audio clip into segments of 5 second long.\n\ndef segmentize_signal(signal, sr, dur):\n    \"\"\"\n    Segmentize the 1-d signal (mono) to a list of clips with custom duration (dur).\n    \"\"\"\n    seg_len = dur * sr\n\n    # calculate number of segments\n    no_segs = len(signal) // seg_len\n\n\n    # truncate input signal to have length divisiable by seg_len\n    trunc_len = int(no_segs * seg_len)\n\n    # split equally\n    return np.split(signal[:trunc_len], no_segs)\n\ndef save_audio(signal, sr, output_dir, filename):\n    output_path = os.path.join(output_dir, filename)\n    # torchaudio.save(output_path, signal, sr)\n    # print(output_path, sr)\n    sf.write(output_path, signal, sr)\n\ndef segment_audio_file(audio_path, output_dir,  target_sr=TARGET_SR, segment_duration=SEGMENT_DURATION):\n    print(f\"Processing raw clip: {audio_path}\")\n    signal, _ = librosa.load(audio_path, sr=target_sr, mono=True)\n    # signal, target_sr = librosa.load(audio_path,sr=None,  mono=True)\n    print(f\"\\tLoaded clip from disk\")\n    segments_list = segmentize_signal(signal, target_sr, segment_duration)\n    print(f\"\\tSegmented clip into {len(segments_list)} segments\")\n    for seg_idx, seg in enumerate(segments_list):\n        seg_name = f\"{audio_path.split('/')[-1][:-4]}_{seg_idx}.wav\"\n        save_audio(seg, target_sr, output_dir, seg_name)\n    print(f\"\\tSegments are saved completely\")\n\nNext, we use threading to segmentize all clips at the same time. Beware that if your system has less than 32GB of RAM, this could cause the system to freeze and run out of memory. In such case, please modify the code before do it sequentially (i.e. without threading)\n\nthread_list = []\n\nfor cls in CLASSES:\n# get all raw files from subfolders\n    raw_audio_paths = glob(f\"{RAW_CLIP_PATH}{cls}/*mp3\")\n    for audio_path in raw_audio_paths:\n        output_dir = f\"{SEGMENT_DIR}{cls}\"\n        new_thread = threading.Thread(target=segment_audio_file, args=(audio_path, output_dir))\n        thread_list.append(new_thread)\n        \nprint(\"Segmentation starting...\")\n# start each thread\nfor thread in thread_list:\n  thread.start()\n\n# wait for all to finish\nfor thread in thread_list:\n  thread.join()\n\n# successfully excecuted\nprint(\"Segmentation finished!\")\n\nSegmentation starting...\nProcessing raw clip: /workspace/data/raw/nylon/qXwvz-nTiog.mp3\nProcessing raw clip: /workspace/data/raw/nylon/6jQ34uTmA9s.mp3\nProcessing raw clip: /workspace/data/raw/nylon/qgb-bdEEI-M.mp3\nProcessing raw clip: /workspace/data/raw/steel/IP8vBL5Q8Ac.mp3\nProcessing raw clip: /workspace/data/raw/steel/foIPN-T7RGo.mp3\n\n\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n\n\nProcessing raw clip: /workspace/data/raw/steel/10ATKnZLg9c.mp3\n\n\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n\n\n    Loaded clip from disk\n    Segmented clip into 648 segments\n    Segments are saved completely\n    Loaded clip from disk\n    Segmented clip into 742 segments\n    Segments are saved completely\n    Loaded clip from disk\n    Segmented clip into 1230 segments\n    Segments are saved completely\n    Loaded clip from disk\n    Segmented clip into 1251 segments\n    Segments are saved completely\n    Loaded clip from disk\n    Segmented clip into 1427 segments\n    Segments are saved completely\n    Loaded clip from disk\n    Segmented clip into 2647 segments\n    Segments are saved completely\nSegmentation finished!"
  },
  {
    "objectID": "posts/steel-nylon-classifier.html#create-annotations",
    "href": "posts/steel-nylon-classifier.html#create-annotations",
    "title": "Simple MLP model for Guitar Steel vs Nylon strings classification",
    "section": "5.1 Create annotations",
    "text": "5.1 Create annotations\nBefore creating our own dataset class, we need to have a csv file to describe our training / val / test sets.\nThis annotation dataframe stores the paths to each audio sample and its label:\n\nannotation_dict = {\"audio_path\": [], \"label\": []}\n\n\nfor label, cls in enumerate(CLASSES):\n  wav_dirs = f\"{SEGMENT_DIR}{cls}/*wav\"\n  audio_path_list = glob(wav_dirs)\n  count_audio_files = len(audio_path_list)\n  label_list = [label] * count_audio_files\n\n  annotation_dict[\"audio_path\"] += audio_path_list\n  annotation_dict[\"label\"]      += label_list\n\n\nannotation_df = pd.DataFrame.from_dict(annotation_dict)\nannotation_df.tail()\n\n\n\n\n\n  \n    \n      \n      audio_path\n      label\n    \n  \n  \n    \n      7940\n      ./data/segments/steel/foIPN-T7RGo_575.wav\n      1\n    \n    \n      7941\n      ./data/segments/steel/10ATKnZLg9c_545.wav\n      1\n    \n    \n      7942\n      ./data/segments/steel/10ATKnZLg9c_1035.wav\n      1\n    \n    \n      7943\n      ./data/segments/steel/10ATKnZLg9c_602.wav\n      1\n    \n    \n      7944\n      ./data/segments/steel/IP8vBL5Q8Ac_1146.wav\n      1\n    \n  \n\n\n\n\nThe data is quite enormously for an average system. That’s why I seperated the training data set to full, half, quarter, and one eighth. This allows me to build and test model fast (by using a smaller training dataset). When I find something that works well, I can then use a larger training dataset to improve the training.\n\ntrain_df_full = annotation_df.sample(frac=TRAIN_SIZE, random_state=RANDOM_SEED)\nval_df = annotation_df.drop(train_df_full.index, axis=0)\n\n# make smaller train datasets for quick experimentations\ntrain_df_half = train_df_full.sample(frac=1/2, random_state=RANDOM_SEED)\ntrain_df_quarter = train_df_full.sample(frac=1/4, random_state=RANDOM_SEED)\ntrain_df_1eight = train_df_full.sample(frac=1/8, random_state=RANDOM_SEED)\n\nWe have 4816 samples of NYLON, and 3129 of STEEL\n\nannotation_df[\"label\"].value_counts()\n\n0    4816\n1    3129\nName: label, dtype: int64\n\n\nFinally, let’s write them to CSV files for later use.\n\ndf_list = [train_df_full, train_df_half, train_df_quarter, train_df_1eight, val_df]\n\ndf_names = [\"train_df_full\", \"train_df_half\", \"train_df_quarter\", \"train_df_1eight\", \"val_df\"]\n\nfor df_name, df_content in zip(df_names, df_list):\n    df_content.to_csv(f\"{DATA_DIR}{df_name}.csv\", index=False)"
  },
  {
    "objectID": "posts/steel-nylon-classifier.html#dataset-class",
    "href": "posts/steel-nylon-classifier.html#dataset-class",
    "title": "Simple MLP model for Guitar Steel vs Nylon strings classification",
    "section": "5.2 Dataset class",
    "text": "5.2 Dataset class\nWe create GuitarSoundDataset which inherets Dataset from PyTorch. This class holds the annotation that we created earlier and helps us access and preprocess each individual input and label.\nTo create this class, I took inspiration from this awesome Deep Learning for Audio channel: https://www.youtube.com/watch?v=iCwMQJnKk2c&t=1s&ab_channel=ValerioVelardo-TheSoundofAI\n\nfrom torch.utils.data import Dataset\n\nclass GuitarSoundDataset(Dataset):\n\n    def __init__(self,\n                 annotations_file,\n                 transformation,\n                 target_sample_rate,\n                 num_samples,\n                 device,\n                 audio_col=\"audio_path\",\n                 label_col=\"label\"):\n        self.annotations = pd.read_csv(annotations_file)\n        self.device = device\n        if transformation:\n          self.transformation = transformation.to(self.device)\n        else:\n          self.transformation = None\n        self.target_sample_rate = target_sample_rate\n        self.num_samples = num_samples\n        self.audio_col = audio_col\n        self.label_col = label_col\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        audio_sample_path = self.__get_audio_sample_path(index)\n        label = self.__get_audio_sample_label(index)\n        signal, sr = torchaudio.load(audio_sample_path)\n        if signal.dim() < 2:\n          signal = signal[None, :]\n        signal = signal.to(self.device)\n        signal, sr = self.preprocess_signal(signal, sr)\n        if self.transformation:\n          signal = self.transformation(signal)\n        return signal, label\n\n    def preprocess_signal(self, signal, sr):\n        signal = self.__resample_if_necessary(signal, sr)\n        signal = self.__mix_down_if_necessary(signal)\n        signal = self.__cut_if_necessary(signal)\n        signal = self.__right_pad_if_necessary(signal)\n        return signal, sr\n\n    def __cut_if_necessary(self, signal):\n        if signal.shape[1] > self.num_samples:\n            signal = signal[:, :self.num_samples]\n        return signal\n\n    def __right_pad_if_necessary(self, signal):\n        length_signal = signal.shape[1]\n        if length_signal < self.num_samples:\n            num_missing_samples = self.num_samples - length_signal\n            last_dim_padding = (0, num_missing_samples)\n            signal = torch.nn.functional.pad(signal, last_dim_padding)\n        return signal\n\n    def __resample_if_necessary(self, signal, sr):\n        if sr != self.target_sample_rate:\n            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate).to(self.device)\n            signal = resampler(signal)\n        return signal\n\n    def __mix_down_if_necessary(self, signal):\n        if signal.shape[0] > 1:\n            signal = torch.mean(signal, dim=0, keepdim=True)\n        return signal\n\n    def __get_audio_sample_path(self, index):\n        path = self.annotations.iloc[index, :][self.audio_col]\n        return path\n\n    def __get_audio_sample_label(self, index):\n        label =  self.annotations.iloc[index, :][self.label_col]\n        return torch.tensor(label, dtype=torch.float)"
  },
  {
    "objectID": "posts/steel-nylon-classifier.html#dataloader",
    "href": "posts/steel-nylon-classifier.html#dataloader",
    "title": "Simple MLP model for Guitar Steel vs Nylon strings classification",
    "section": "5.3 DataLoader",
    "text": "5.3 DataLoader\n\nfrom torch.utils.data import DataLoader\n\ndef create_data_loader(dataset, batch_size):\n    dataset_loader = DataLoader(dataset, batch_size=batch_size)\n    return dataset_loader\n\nMel Spectrogram transforms our signal from time-domain into frequency-domain, which helps not only human but also computers to understand the characteristic of sound input better. Thus, we need to transform each audio input into mel spec before feeding it into the neural network.\n\nmel_spectrogram = torchaudio.transforms.MelSpectrogram(\n      sample_rate=TARGET_SR,\n      n_fft=1024,\n      hop_length=512,\n      n_mels=64\n  )\n\ntrain_dataset = GuitarSoundDataset(\n                      annotations_file =f\"{DATA_DIR}train_df_half.csv\",\n                      transformation = mel_spectrogram,\n                      target_sample_rate = TARGET_SR,\n                      num_samples = TARGET_SR * SEGMENT_DURATION,\n                      device = device)\nprint(f\"There are {len(train_dataset)} samples in the TRAIN dataset.\")\n\nval_dataset = GuitarSoundDataset(f\"{DATA_DIR}val_df.csv\",\n                      transformation = mel_spectrogram,\n                      target_sample_rate = TARGET_SR,\n                      num_samples = TARGET_SR * SEGMENT_DURATION,\n                      device = device)\nprint(f\"There are {len(val_dataset)} samples in the VAL dataset.\")\n\nThere are 3774 samples in the TRAIN dataset.\nThere are 397 samples in the VAL dataset.\n\n\nWe will take one sample out to find out the exact input shape for our neural network\n\nsignal_sample, _ = val_dataset[0]\nsignal_sample.shape\n\ntorch.Size([1, 64, 79])"
  },
  {
    "objectID": "posts/steel-nylon-classifier.html#training-loop",
    "href": "posts/steel-nylon-classifier.html#training-loop",
    "title": "Simple MLP model for Guitar Steel vs Nylon strings classification",
    "section": "6.1 Training Loop",
    "text": "6.1 Training Loop\nBecause the training and validating loops are pretty basic, I don’t delve into these code too much. The official tutorial is where I took inspiration from: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n\ndef compute_accuracy(preds, target):\n  _preds = preds.detach().cpu().numpy()\n  _target = target.detach().cpu().numpy()\n  return np.mean(_preds.squeeze().round() == _target.squeeze())\n\ndef train_single_epoch(model, data_loader, loss_fn, optimiser, device):\n  size = len(data_loader.dataset)\n  train_losses = []\n  train_accs = []\n\n  model.train(True)\n  for batch, (input, target) in enumerate(data_loader):\n      input, target = input.to(device), target.to(device)\n\n      # calculate loss\n      preds = model(input)\n      loss = loss_fn(preds.squeeze(), target.squeeze())\n      train_losses.append(loss.item())\n\n\n      # backpropagate error and update weights\n      optimiser.zero_grad()\n      loss.backward()\n      optimiser.step()\n\n      # calculate accuracy\n      acc = compute_accuracy(preds, target)\n      train_accs.append(acc)\n\n  return np.mean(train_losses), np.mean(train_accs)\n\ndef validate(model, data_loader, loss_fn, device):\n  # model.train(False)\n  val_losses = []\n  val_accs = []\n  with torch.inference_mode():\n    for input, target in data_loader:\n      input, target = input.to(device), target.to(device)\n\n      # calculate loss\n      preds = model(input)\n      loss = loss_fn(preds.squeeze(), target.squeeze())\n      val_losses.append(loss.item())\n\n      # calculate acc\n      acc = compute_accuracy(preds, target)\n      val_accs.append(acc)\n\n    return np.mean(val_losses), np.mean(val_accs)\n\ndef save_model(model, model_dir):\n  torch.save(model.state_dict(), model_dir)\n\ndef train(model, train_dataloader, test_dataloader, loss_fn, optimiser, device, epochs, save_best=True, model_dir=\"bestmodel.pth\"):\n  train_losses = []\n  train_accs = []\n  val_losses = []\n  val_accs = []\n  for i in range(epochs):\n      # training\n      train_loss, train_acc = train_single_epoch(model, train_dataloader, loss_fn, optimiser, device)\n      # val\n      val_loss, val_acc = validate(model, test_dataloader, loss_fn, device)\n      print(f\"Epoch {i+1} | train loss: {train_loss:.5f}, train acc: {train_acc:.3%} | val loss: {val_loss:.5f}, val acc: {val_acc:.3%}\")\n\n      # save best val acc\n      if save_best and len(val_losses) > 0 and val_acc > np.max(val_accs):\n        # save model\n        print(\"-> Best Model found! Saving to disk...\")\n        save_model(model, model_dir)\n\n      # update losses\n      train_losses.append(train_loss)\n      val_losses.append(val_loss)\n      train_accs.append(train_acc)\n      val_accs.append(val_acc)\n  print(\"Finished training\")\n  return train_losses, train_accs, val_losses, val_accs\n\n\ndef plot_model(model_history):\n    train_losses, train_accs, val_losses, val_accs = model_history\n    # Plot Loss\n    plt.plot(range(len(train_losses)), train_losses, label='Training Loss')\n    plt.plot(range(len(train_losses)), val_losses, label='Validation Loss')\n    \n    # Add in a title and axes labels\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(loc=\"upper left\")\n    plt.show()    \n    \n    # Plot Acc\n    plt.plot(range(len(train_accs)), train_accs, label='Training Acc')\n    plt.plot(range(len(train_accs)), val_accs, label='Validation Acc')\n    \n    # Add in a title and axes labels\n    plt.title('Training and Validation Acc')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(loc=\"upper left\")\n    plt.show()\n    \ndef describe_model_stats(model_history):\n    train_losses, train_accs, val_losses, val_accs = model_history\n    history = {\"train_losses\": train_losses, \"train_accs\": train_accs, \"val_losses\": val_losses, \"val_accs\": val_accs}\n    print(pd.DataFrame.from_dict(history).describe())"
  },
  {
    "objectID": "posts/steel-nylon-classifier.html#mlp-model-building-2-hidden-layers-with-relu-activation",
    "href": "posts/steel-nylon-classifier.html#mlp-model-building-2-hidden-layers-with-relu-activation",
    "title": "Simple MLP model for Guitar Steel vs Nylon strings classification",
    "section": "6.2 MLP Model Building: 2 hidden layers with ReLu Activation",
    "text": "6.2 MLP Model Building: 2 hidden layers with ReLu Activation\nI define a simple MLP with 2 hidden fully connected layers with relu activation. The final output is then taken by sigmoid to produce probabily prediction.\n\nfrom torch import nn\nfrom torchsummary import summary\n\n\nclass MLPNetwork(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear = nn.Sequential(\n            nn.Linear(1 * 64 * 79, 256), # I got the number (1 * 64 * 79) as input size from the code above\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1),\n        )\n\n    def forward(self, input_data):\n        x = self.flatten(input_data)\n        logits = self.linear(x)\n        predictions = torch.sigmoid(logits)\n        return predictions\n        # return x\n\n\nif __name__ == \"__main__\":\n    model2 = MLPNetwork()\n    summary(model2.to(device), (1, 64, 79))\n\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n           Flatten-1                 [-1, 5056]               0\n            Linear-2                  [-1, 256]       1,294,592\n              ReLU-3                  [-1, 256]               0\n            Linear-4                  [-1, 128]          32,896\n              ReLU-5                  [-1, 128]               0\n            Linear-6                    [-1, 1]             129\n================================================================\nTotal params: 1,327,617\nTrainable params: 1,327,617\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.02\nForward/backward pass size (MB): 0.04\nParams size (MB): 5.06\nEstimated Total Size (MB): 5.13\n----------------------------------------------------------------\n\n\nAudio input is complex, with an audio sample of 5-second long at 8000 Hz sampling rate, we have an input of 5056 already.\nAnd, this simple MLP model already has 1.3+ millions params.\nNow, let’s create a folder to store our trained params.\n\nMODEL_DIR = f\"{ROOT_DIR}weights/\"\n\nif not os.path.exists(MODEL_DIR):\n    os.makedirs(MODEL_DIR)\n\nThen, define some hyper params for training and create dataloader for each training and validation dataset\n\nBATCH_SIZE = 128\nEPOCHS = 15\nLEARNING_RATE = 0.001\n    \ntrain_dataloader = create_data_loader(train_dataset, BATCH_SIZE)\nval_dataloader = create_data_loader(val_dataset, BATCH_SIZE)\n\nNow, let’s train our model!\n\nMODEL_SAVE_PATH = f\"{MODEL_DIR}model_mlp1.pth\"\nprint(f\"Best models will saved to: {MODEL_DIR} (based on val acc)\")\n\nmodel1 = MLPNetwork()\n\n\nif os.path.exists(MODEL_SAVE_PATH):\n  model1.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=torch.device(device)))\n\nmodel1 = model1.to(device)\n\n# initialise loss funtion + optimiser\nloss_fn = nn.BCELoss()\n\noptimiser = torch.optim.Adam(model1.parameters(),\n                                lr=LEARNING_RATE)\n\n# train model\nhistory_model1 = train(model1, train_dataloader, val_dataloader, loss_fn, optimiser, device, EPOCHS, save_best=True, model_dir=MODEL_SAVE_PATH)\n\nBest models will saved to: ./weights/ (based on val acc)\nEpoch 1 | train loss: 18.60054, train acc: 74.353% | val loss: 18.41207, val acc: 79.943%\nEpoch 2 | train loss: 16.17105, train acc: 80.607% | val loss: 14.15756, val acc: 82.287%\n-> Best Model found! Saving to disk...\nEpoch 3 | train loss: 16.04773, train acc: 79.716% | val loss: 22.44626, val acc: 72.251%\nEpoch 4 | train loss: 15.91658, train acc: 80.841% | val loss: 24.57104, val acc: 72.446%\nEpoch 5 | train loss: 15.68584, train acc: 81.720% | val loss: 26.59615, val acc: 71.274%\nEpoch 6 | train loss: 17.09794, train acc: 80.188% | val loss: 15.84533, val acc: 81.671%\nEpoch 7 | train loss: 15.53885, train acc: 82.014% | val loss: 15.38519, val acc: 80.364%\nEpoch 8 | train loss: 12.86597, train acc: 84.409% | val loss: 19.71215, val acc: 75.931%\nEpoch 9 | train loss: 12.15642, train acc: 85.247% | val loss: 13.57315, val acc: 81.926%\nEpoch 10 | train loss: 11.81812, train acc: 84.438% | val loss: 12.96833, val acc: 81.145%\nEpoch 11 | train loss: 10.44457, train acc: 86.577% | val loss: 10.41160, val acc: 82.677%\n-> Best Model found! Saving to disk...\nEpoch 12 | train loss: 8.54932, train acc: 88.063% | val loss: 7.47481, val acc: 84.826%\n-> Best Model found! Saving to disk...\nEpoch 13 | train loss: 7.18438, train acc: 88.478% | val loss: 6.82821, val acc: 83.263%\nEpoch 14 | train loss: 5.54964, train acc: 89.264% | val loss: 4.69765, val acc: 84.405%\nEpoch 15 | train loss: 2.19403, train acc: 89.026% | val loss: 1.49113, val acc: 84.075%\nFinished training\n\n\n\ndescribe_model_stats(history_model1)\nplot_model(history_model1)\n\n       train_losses  train_accs  val_losses   val_accs\ncount     15.000000   15.000000   15.000000  15.000000\nmean      12.388064    0.836627   14.304709   0.798988\nstd        4.770562    0.042507    7.314085   0.046287\nmin        2.194033    0.743532    1.491129   0.712740\n25%        9.496942    0.807237    8.943201   0.779372\n50%       12.865967    0.844086   14.157557   0.816707\n75%       15.982155    0.873198   19.062112   0.829703\nmax       18.600537    0.892641   26.596150   0.848257"
  },
  {
    "objectID": "posts/vietnamese-lyrics-classifier.html",
    "href": "posts/vietnamese-lyrics-classifier.html",
    "title": "Vietnamese Lyrics Classification",
    "section": "",
    "text": "Liệu rằng phần lời của một bài hát có đầy đủ thông tin để chúng ta phân loại chủ đề bài hát đó? Trong bài viết này, chúng ta sẽ dùng machine learning để trả lời câu hỏi này với các phương pháp Logistic Regression (PyTorch) / Naive Bayes / Genetic Algorithm / Decision Tree nhé!"
  },
  {
    "objectID": "posts/vietnamese-lyrics-classifier.html#trích-xuất-dữ-liệu",
    "href": "posts/vietnamese-lyrics-classifier.html#trích-xuất-dữ-liệu",
    "title": "Vietnamese Lyrics Classification",
    "section": "2.1 Trích xuất dữ liệu",
    "text": "2.1 Trích xuất dữ liệu\nCảm ơn loibaihathot.com đã có một kho lời bài hát khá nhiều và dễ trích xuất. Tất cả những gì chúng ta cần chỉ là thư viện requests để lấy nội dung html của trang web. Và, BeautifulSoup để parse nội dung html ra element cho dễ trích xuất.\n\n# Import thư viện cần thiết\n\nimport requests\nimport time\nimport csv\nimport re\nfrom bs4 import BeautifulSoup\n\nXác định 1 số chủ đề có sẵn trên trang web để tài về. Base URL sẽ là url gốc, từ đây chúng ta replace {genre} để tải lời cho bài hát thuộc chủ đề tương ứng.\nLưu ý: Ở đây mình dùng từ genre không sát nghĩa “chủ đề” đâu nghen.\n\ngenre_list = ['cach-mang', 'que-huong', 'thieu-nhi', 'tre']\n\nbase_url = \"https://loibaihathot.com/{genre}\"\n\nTiếp theo, chúng ta tải hết tất cả các URL của các bài hát, phân loại theo chủ đề\n\nlyric_url_list = {}\n\nfor genre in genre_list:\n  url = base_url.format(genre=genre)\n  html_text = requests.get(url).text\n  soup = BeautifulSoup(html_text, 'html.parser')\n  all_links = list(map(lambda e: e['href'], soup.find_all('a')))\n  lyric_url_list[genre] = list(set(filter(lambda url: '/20' in url, all_links)))\n\nTạo thư mục data để lưu trữ dữ liệu, tránh việc phải chạy Trích xuất lại lần nữa:\n\nimport os\n\nDATA_FOLDER = 'data/'\n\ndef create_path_if_nonexist(path):\n  if not os.path.exists(path):\n    os.mkdir(path)\n\ncreate_path_if_nonexist(DATA_FOLDER)\n\nViết hàm để tải nội dung lời bài hát cho một bài hát, với input là đường dẫn đến bài hát đó:\n\nimport re\n\ndef download_lyric(song_url):\n  html_text = requests.get(song_url).text\n  soup = BeautifulSoup(html_text, 'html.parser')\n  lyric = soup.find('div', class_=\"entry-content content mt-6\").get_text(separator = '\\n', strip = True)\n  lyric = re.sub('\\n.+','',lyric, count=3).strip()\n  return lyric\n\nCòn đây là hàm để tải lời nhiều bài cùng 1 lúc, hàm này sẽ dùng để phân luồng threading -> tăng tốc download:\n\ndef download_songs(song_urls, genre):\n  full_path = os.path.join(DATA_FOLDER, genre)\n  create_path_if_nonexist(full_path)\n  for url in song_urls:\n    lyric = download_lyric(url)\n    if len(lyric) < 10:\n      continue\n    file_name =re.findall('/[^\\/]+$', url)[0][1:-5]\n    with open(f'{full_path}/{file_name}.txt', 'w') as f:\n      f.write(lyric)\n\nVới mỗi chủ đề, chúng ta sẽ dùng threading để tải hết lời bài hát về. Để tải nhanh hơn, chúng ta có thể chia thêm nhiều threads con nữa. Nhưng mình muốn mọi thứ đơn giản trước đã:\n\nimport threading\n\nthread_list = []\n\n# create list of threads\nfor genre in genre_list:\n  thread = threading.Thread(target=download_songs, args=(lyric_url_list[genre],genre))\n  thread_list.append(thread)\n\nprint(\"Download starting...\")\n# start each thread\nfor thread in thread_list:\n  thread.start()\n\n# wait for all to finish\nfor thread in thread_list:\n  thread.join()\n\n# successfully excecuted\nprint(\"Download finished!\")\n\nDownload starting...\nDownload finished!"
  },
  {
    "objectID": "posts/vietnamese-lyrics-classifier.html#tiền-xử-lý-pre-processing",
    "href": "posts/vietnamese-lyrics-classifier.html#tiền-xử-lý-pre-processing",
    "title": "Vietnamese Lyrics Classification",
    "section": "2.2 Tiền xử lý (Pre-processing)",
    "text": "2.2 Tiền xử lý (Pre-processing)\nSau khi mình và train thử cho bộ dữ liệu ban đầu thì thấy độ chính xác đều dưới 20%. Kiểm tra lại thì thấy có nhiều bài download về vào sai thư mục chủ đề. Điều này có thể gây nhiễu dữ liệu, nên chúng ta sẽ xóa thủ xông những files sau để tăng độ chính xác khi huấn luyện:\n\n# Clean-up data\n\nto_delete = {\n    \"thieu-nhi\":[\n        \"cam-on-nguoi-da-roi-xa-toi.txt\",\n        \"chac-ai-do-se-ve.txt\",\n        \"dung-tin-em-manh-me.txt\",\n        \"hay-ra-khoi-nguoi-do-di.txt\",\n        \"khuon-mat-dang-thuong.txt\",\n    ],\n    \n    \"cach-mang\":[\n        \"cam-on-nguoi-da-roi-xa-toi.txt\",\n        \"chac-ai-do-se-ve.txt\",\n        \"dung-tin-em-manh-me.txt\",\n        \"hay-ra-khoi-nguoi-do-di.txt\",\n        \"khuon-mat-dang-thuong.txt\",\n    ],\n    \n    \"que-huong\":[\n        \"cam-on-nguoi-da-roi-xa-toi.txt\",\n        \"chac-ai-do-se-ve.txt\",\n        \"dung-tin-em-manh-me.txt\",\n        \"hay-ra-khoi-nguoi-do-di.txt\",\n        \"khuon-mat-dang-thuong.txt\",\n    ],\n\n}\n\nfor subfolder, filenames in to_delete.items():\n    for filename in filenames:\n      try:\n        filepath = f\"{DATA_FOLDER}{subfolder}/{filename}\"\n        os.remove(filepath)\n      except Exception as e:\n        print(e)\n\nCài thêm thư viện underthesea để hỗ trợ tokenize ngôn ngữ Việt:\n\n!pip install -q underthesea==1.3.5a3\n\nTiền xử lý lời bài hát, chủ yếu là xóa ký tự đặc biệt:\n\ndef preprocess_lyric(text):\n  # remove special characters\n  import re\n  text = re.sub('[^\\w\\s]','', text).lower()\n  return text\n\npreprocess_lyric('Ngày mai??!! 13 em đi!')\n\n'ngày mai 13 em đi'"
  },
  {
    "objectID": "posts/vietnamese-lyrics-classifier.html#xây-dựng-mô-hình",
    "href": "posts/vietnamese-lyrics-classifier.html#xây-dựng-mô-hình",
    "title": "Vietnamese Lyrics Classification",
    "section": "3.1 Xây dựng mô hình",
    "text": "3.1 Xây dựng mô hình\nChúng ta import những library cần thiết của PyTorch\n\nimport torch\nimport matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch import optim\nfrom torchvision import datasets, transforms\n\nseed = 69\ntorch.manual_seed(seed)\n\n<torch._C.Generator at 0x7f4a9c335130>\n\n\nKhai báo mô hình gồm 2 lớp: 1. Linear: Nhận input là tensor của bài hát được tokenize thành tensor có n_features và output là tensor có số chiều là n_labels tương ứng với số lượng chủ đề cần phân loại 2. LogSoftMax: Đây là dạng activation function cho bài toán phân loại đa lớp\n\nmodel = nn.Sequential(nn.Linear(n_features, n_labels),nn.LogSoftmax(dim=1))\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\nHàm tính độ chính xác của mô hình:\n\ndef calculate_accuracy(model, X, labels):\n  y_hat = model(torch.as_tensor(X).float())\n  preds = y_hat.max(axis=1, keepdim=True)[1].numpy().squeeze()\n  correct = np.sum(preds == labels)\n  accuracy = correct / len(labels)\n  return accuracy\n\nTiến hành train model\n\nepochs = 300\n\nlosses = []\naccs = []\nfor e in range(epochs+1):\n  optimizer.zero_grad()\n  # tính y_hat\n  output = model(X_train_tensor)\n\n  # tính loss\n  loss = criterion(output, y_train_onehot_tensor)\n\n  # tính gradient\n  loss.backward()\n\n  # tối ưu gradient\n  optimizer.step()\n\n  # cập nhật loss\n  running_loss = loss.item()\n  losses.append(running_loss)\n\n  # tính accuracy\n  acc = calculate_accuracy(model, X_test, y_test)\n  accs.append(acc)\n\n  # in thông số training\n  if e % 100 == 0:\n    print(f\"Training epoch {e} : loss: {running_loss:.3f}; accuracy: {acc:.2%}\")\n\nTraining epoch 0 : loss: 9201.797; accuracy: 40.00%\nTraining epoch 100 : loss: 16386.709; accuracy: 76.67%\nTraining epoch 200 : loss: 6421.723; accuracy: 56.67%\nTraining epoch 300 : loss: 906.633; accuracy: 86.67%\n\n\nMô hình chúng ta sau khi train 300 epoch có accuracy 86.67%.\n\nplt.plot(losses)\nplt.xlabel('epoch')\nplt.ylabel('Loss')\nplt.title('Model losses over time (epoch)')\nplt.show()\n\n\n\n\n\nplt.plot(accs)\nplt.xlabel('epochs')\nplt.ylabel('Loss')\nplt.title('Model accuracy over time (epoch)')\nplt.show()\n\n\n\n\nHàm sau dùng để phân loại lời bài hát bất kỳ.\n\ndef predict_label(model, lyric):\n  x = lyric_to_features(lyric, n_labels)\n  y_hat = model(torch.as_tensor(np.array([x])).float())\n  pred = y_hat.max(axis=1, keepdim=True)[1].numpy().squeeze()\n  return genre_list[pred]"
  },
  {
    "objectID": "posts/vietnamese-lyrics-classifier.html#predict",
    "href": "posts/vietnamese-lyrics-classifier.html#predict",
    "title": "Vietnamese Lyrics Classification",
    "section": "3.2 Predict",
    "text": "3.2 Predict\nỞ đây chúng ta sẽ phân loại thử một số bài hát một ách cách thủ công nhé.\nĐây là bài “Hát về anh”, thuộc thể loại cách mạng. Mô hình đã phân loại chính xác trường hợp này.\n\nlyric = '''Hát Về Anh\nMột ba lô, cây súng trên vai,\nNgười chiến sĩ quen với gian lao,\nNgày dài đêm thâu vẫn có những người lính trẻ,\nNặng tình quê hương canh giữ trên miền đất mẹ.\nRừng âm u, mây núi mênh mông\nNgày nắng cháy, đêm giá lạnh đầy.\nRừng mờ sương khuya bóng tối quân thù trước mặt,\nNặng tình non sông anh dâng trọn tuổi đời thanh xuân.\nCho em thơ ngủ ngon và vui bước sớm hôm đến trường\nCho yên vui mùa xuân đôi lứa còn hẹn hò ước mơ\nÐã có những hy sinh khó nói hết bằng lời\nNên đọng lại trong tôi những nghĩ suy.\nCho tôi bài ca về người chiến sĩ nơi tuyến đầu.\nNơi biên cường rừng sâu, anh âm thầm chịu đựng gió sương.\nĐã có những gian lao, đã có những nhọc nhằn\nMang trong trái tim anh trọn niềm tin.\nXin hát mãi về anh người chiến sĩ biên cương\nXin hát mãi về anh người chiến sĩ biên cương\nNghe lời bài hát Hát Về Anh\nHát Về Anh '''\n\npredict_label(model, lyric)\n\n'cach-mang'\n\n\nBài hát Dây Đủng Đỉnh Buồn được phân loại Quê Hương trong dữ liệu. Đây cũng là một dự đoán chính xác.\n\nlyric = '''Dây Đủng Đỉnh Buồn (Remix)\nEm đi theo chồng xa thôn làng cách biệt dòng sông.\nEm đi theo chồng anh nơi này mỏi mon` đợi trông\nNhư dây đủng đỉnh nuôi trái tình bào tháng ngày qua.\nTình đã trọng xanh rồi người nỡ đem đi hái cho đành.\nAi xuôi chỉ mình ôm nỗi buồn cho người ta vui.\nAi xuôi chỉ mình xây duyên tình giờ đây lẻ loi.\nNhìn con nước chảy theo con thuyền lạc bến đời nhau.\nLời ước hẹn xưa giờ thì cũng xa xa cuối chân trời.\nĐK:\nĐau thương thui thủi đêm trương, gió lạnh từng đêm lẻ bóng đơn côi.\nBuồn miên man thầm trách cho đời lơ lửng chi rồi bỏ bạn mình ên.\nYêu thương xin trả cho người nuốt lệ nhìn theo đám cưới người ta.\nĐể bên đây đủng đỉnh u buồn, sao mang ân tình trao tặng người ta.\nNghe lời bài hát Dây Đủng Đỉnh Buồn (Remix)\n\n \nDây Đủng Đỉnh Buồn (Remix)'''\n\npredict_label(model, lyric)\n\n'que-huong'\n\n\nBài hát thiếu nhi này cũng được phân loại đúng:\n\nlyric = '''Ai yêu bác Hồ Chí Minh hơn thiếu nhi Việt Nam\nBác chúng em dáng cao cao, người thanh thanh\nBác chúng em mắt như sao, râu hơi dài\nBác chúng em nước da nâu vì sương gió\nBác chúng em thề cương quyết trả thù nhà\nHồ Chí Minh kính yêu, chúng em kính yêu Bác Hồ Chí Minh trọn một đời\nHồ Chí Minh kính yêu Bác đã bao phen bôn ba nước ngoài vì giống nòi\nBác nay tuy đã già rồi\nGià rồi nhưng vẫn vui tươi\nNgày ngày chúng cháu ước mơ\nMong sao Bác sống muôn đời để dẫn dắt nhi đồng thành người và kiến thiết nước nhà bằng Người\nHồ Chí Minh kính yêu, chúng em kính yêu Bác Hồ Chí Minh trọn một đời\nHồ Chí Minh kính yêu, chúng em ước sao Bác Hồ Chí Minh sống muôn đời\nAi Yêu Bác Hồ Chí Minh Hơn Chúng Em Nhi Đồng'''\n\npredict_label(model, lyric)\n\n'thieu-nhi'\n\n\nBài hát “Ánh nắng của anh” được phân loại chính xác cho thể loại “Trẻ”\n\nlyric = '''Những phút giâу trôi qua tầm taу\nϹhờ một ai đó đến bên anh\nLặng nghe những tâm tư nàу\nLà tia nắng ấm\nLà em đến bên anh cho vơi đi ưu phiền ngàу hôm qua\nNhẹ nhàng xóa đi bao mâу đen vâу quanh cuộc đời nơi anh\nPhút giâу anh mong đến tình уêu ấу\nGiờ đâу là em, người anh mơ ước bao đêm\nЅẽ luôn thật gần bên em\nЅẽ luôn là vòng taу ấm êm\nЅẽ luôn là người уêu em\nϹùng em đi đến chân trời\nLắng nghe từng nhịp tim anh\nLắng nghe từng lời anh muốn nói\nVì em luôn đẹp nhất khi em cười'''\n\npredict_label(model, lyric)\n\n'tre'\n\n\nBây giờ mình sẽ lấy 2 bài hát không trong tập dữ liệu\nBài thứ nhất là một bài nhạc trẻ mới nổi gần đây “Anh Chưa Thương Em Đến Vậy Đâu”:\n\nlyric = '''Sao mình không gạt bỏ đi hết những lời nói ngoài kia\nVà sao mình không gạt bỏ đi hết những định kiến ngoài kia\n\nGiữa ngân hà em biết đâu là\nBiết đâu là thế gian này mà\nMình bên nhau, được yêu nhau, được trao nhau, tình yêu sâu trái tim đậm sâu\n\nGiữa ngân hà em biết đâu là\nBiết đâu một sớm mai khi mà\nCần bao lâu, chờ bao lâu, đợi bao lâu, tình trao nhau mãi thôi đậm sâu\n\nGiữa ngân hà, giữa ngân hà, giữa ngân hà\nBiết đâu là, biết đâu là, biết đâu là\nHành tinh của hai chúng ta\nMột nơi của riêng chúng ta\n\nGiữa ngân hà, giữa ngân hà, giữa ngân hà\nBiết đâu là, biết đâu là, biết đâu là\nHành tinh của hai chúng ta\nỞ 1 thế giới còn rất xa'''\n\npredict_label(model, lyric)\n\n'tre'\n\n\nVới bài hát “Bước qua mùa cô đơn”:\n\nlyric = '''Mùa thu rơi vào em, vào trong giấc mơ hôm qua\nMùa thu ôm mình em, chạy xa vòng tay vội vã\nLời em nói ngày xưa đâu đây\nVẫn âm thầm chìm vào trong mây\nĐến bao giờ, dặn lòng anh không mong nhớ\nMùa thu rơi vào em, vào trong chiếc hôn ngây thơ\nMùa thu không cần anh, vì em giờ đây còn mãi hững hờ\nNgày mai kia nếu có phút giây vô tình thấy nhau sẽ nói câu gì...\nHay ta chỉ nhìn\nLặng lẽ\nĐi qua\nChào cơn mưa\nLàm sao cứ kéo ta quay lại\nNhững rung động con tim\nLần đầu hai ta gặp gỡ'''\n\npredict_label(model, lyric)\n\n'tre'"
  },
  {
    "objectID": "articles.html",
    "href": "articles.html",
    "title": "Articles",
    "section": "",
    "text": "Simple MLP model for Guitar Steel vs Nylon strings classification\n\n\n\n\n\n\n\ncode\n\n\nClassification\n\n\nmlp\n\n\ncnn\n\n\naudio\n\n\nprocessing\n\n\nsignal\n\n\nfft\n\n\n\n\n\n\n\n\n\n\n\nNov 26, 2022\n\n\nLuka Nguyen\n\n\n\n\n\n\n  \n\n\n\n\nVietnamese Lyrics Classification\n\n\n\n\n\n\n\ncode\n\n\nClassification\n\n\ndecision tree\n\n\n\n\n\n\n\n\n\n\n\nOct 21, 2022\n\n\nLuka Nguyen\n\n\n\n\n\n\nNo matching items"
  }
]